{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import IPython\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import Audio, display\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importing features from preprocessing notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/features.csv')\n",
    "\n",
    "print(df.head(1))  \n",
    "print('------------------------------------------------')\n",
    "print(df.columns)  \n",
    "print('------------------------------------------------')\n",
    "print(df.dtypes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('na values\\n', df.isna().sum())\n",
    "print('------------------------------------------------')\n",
    "print(\"number of duplicated values:\\n\", df.duplicated().sum())\n",
    "print('------------------------------------------------')\n",
    "print(\"shape:\\n\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Emotion level value counts\\n', df['Emotion levels'].value_counts())\n",
    "\n",
    "#dropping where emotion level is x\n",
    "idx = df[df['Emotion levels'] == \"X\"].index\n",
    "print(idx)\n",
    "\n",
    "df = df.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emotion levels'].value_counts()\n",
    "\n",
    "#Currently, the data will remain unbalanced; later, emotion levels will be categorized as specified/unspecified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emotion'].value_counts()\n",
    "\n",
    "#it can be concluded that the data is approximately evenly distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Emotion levels'], drop_first=True)\n",
    "dummy_cols = [col for col in df.columns if col.startswith('Emotion levels_')]\n",
    "df[dummy_cols] = df[dummy_cols].astype(int)\n",
    "\n",
    "emotion_mapping = {\n",
    "    'ANG': 0,\n",
    "    'DIS': 1,\n",
    "    'FEA': 2,\n",
    "    'HAP': 3,\n",
    "    'SAD': 4,\n",
    "    'NEU': 5\n",
    "}\n",
    "\n",
    "df['emotion_numeric'] = df['Emotion'].map(emotion_mapping)\n",
    "\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the 'emotion' column, since we included dummy variables\n",
    "df = df.drop(columns=['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expanding columns that contain lists as values\n",
    "list_columns = ['mfcc_mean', 'mfcc_delta_mean', 'mfcc_delta2_mean', 'mel_spec_db_mean']\n",
    "\n",
    "for col in list_columns:\n",
    "    if col not in df.columns:\n",
    "        print(f\"skipping {col}, not found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nworking on: {col}\")\n",
    "    \n",
    "    # sting -> list\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    # num -> list (if num is somewhere)\n",
    "    df[col] = df[col].apply(lambda x: [x] if isinstance(x, (float, int)) else x)\n",
    "        \n",
    "    # max list lenght in the column\n",
    "    max_len = df[col].apply(len).max()\n",
    "    \n",
    "    # filling lists with zeros if neccessary\n",
    "    df[col] = df[col].apply(lambda x: x + [0]*(max_len - len(x)))\n",
    "    \n",
    "    #expanding the df\n",
    "    expanded = pd.DataFrame(df[col].tolist(), index=df.index)\n",
    "    expanded.columns = [f'{col}_{i}' for i in range(max_len)]\n",
    "    \n",
    "    #dropping org columns\n",
    "    df = df.drop(columns=[col])\n",
    "    df = pd.concat([df, expanded], axis=1)\n",
    "    \n",
    "    print(f\"expanding {max_len} new columns.\")\n",
    "\n",
    "print(\"\\nall columns edited properly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "#numeric_cols will be predicted -> no standardization\n",
    "numeric_cols = numeric_cols.drop('emotion_numeric') if 'emotion_numeric' in numeric_cols else numeric_cols\n",
    "\n",
    "print(\"cols for standardization:\", list(numeric_cols))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"\\ndata after the standardization process:\")\n",
    "print(df[numeric_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['spectral_centroid_mean', 'zcr_mean'] + \\\n",
    "               [f'mfcc_delta_mean_{i}' for i in range(3)] + \\\n",
    "               [f'mel_spec_db_mean_{i}' for i in range(3)]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Original {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnecessary column 'location'\n",
    "df = df.drop(columns=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['emotion_numeric'])\n",
    "y = df['emotion_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 220, 250, 270, 300, 305, 310, 320],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "#Best parameters: {'n_estimators': 310}\n",
    "#Best cross-validation score: 0.4450619139343395\n",
    "#Test Accuracy: 0.4432505036937542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf1 = RandomForestClassifier(n_estimators=310, random_state=42)\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = rf1.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmrf1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmrf1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model1 = GaussianNB()\n",
    "nb_model1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_model1.predict(X_test)\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnb1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmnb1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"GaussianNB Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  \n",
    "\n",
    "model1 = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(6, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model1.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=50, batch_size=32, callbacks=[early_stop],\n",
    "          class_weight=class_weights)\n",
    "\n",
    "\n",
    "history = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\nclassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "\n",
    "cmnn1 = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmnn1, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"NN Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 5, 10, 15],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']  \n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "y_pred_svm = best_svc.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "cmsvc1 = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmsvc1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Best parameters: {'C': 15, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "#Best cross-validation score: 0.48437892033387664\n",
    "#Test Accuracy: 0.5023505708529215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model1 = SVC(kernel='rbf', C=15, gamma=0.001)\n",
    "svm_model1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "cmsvc1 = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmsvc1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model1 = LinearDiscriminantAnalysis()\n",
    "lda_model1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lda = lda_model1.predict(X_test)\n",
    "\n",
    "print(\"accuraccy LDA:\", accuracy_score(y_test, y_pred_lda))\n",
    "print(classification_report(y_test, y_pred_lda))\n",
    "\n",
    "cmlda1 = confusion_matrix(y_test, y_pred_lda)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmlda1, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('LDA Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next segment, different data will be used — columns where the values were lists will be modified so that their value is the average of the list, as there is a possibility that dimensionality affects the model’s results. Models of the same architecture will be trained on such data, and then I will attempt to find the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/features.csv')\n",
    "\n",
    "idx = df[df['Emotion levels'] == \"X\"].index\n",
    "print(idx)\n",
    "\n",
    "df = df.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "df = pd.get_dummies(df, columns=['Emotion levels'], drop_first=True)\n",
    "dummy_cols = [col for col in df.columns if col.startswith('Emotion levels_')]\n",
    "\n",
    "df[dummy_cols] = df[dummy_cols].astype(int)\n",
    "\n",
    "\n",
    "emotion_mapping = {\n",
    "    'ANG': 0,\n",
    "    'DIS': 1,\n",
    "    'FEA': 2,\n",
    "    'HAP': 3,\n",
    "    'SAD': 4,\n",
    "    'NEU': 5\n",
    "}\n",
    "\n",
    "df['emotion_numeric'] = df['Emotion'].map(emotion_mapping)\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all cols thah contain lists: replace the list with the list's mean value\n",
    "list_columns = ['mfcc_mean', 'mfcc_delta_mean', 'mfcc_delta2_mean', 'mel_spec_db_mean']\n",
    "\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(lambda x: np.mean(x) if isinstance(x, list) and len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric_cols = numeric_cols.drop('emotion_numeric') if 'emotion_numeric' in numeric_cols else numeric_cols\n",
    "\n",
    "print(\"cols for standardization:\", list(numeric_cols))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"\\ndata after the standardization process:\")\n",
    "print(df[numeric_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['emotion_numeric'])\n",
    "y = df['emotion_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf2 = RandomForestClassifier(n_estimators=310, random_state=42)\n",
    "rf2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = rf2.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmrf2 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmrf2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model2 = GaussianNB()\n",
    "nb_model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_model2.predict(X_test)\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnb2 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmnb2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"GaussianNB Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  \n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(6, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=50, batch_size=32, callbacks=[early_stop],\n",
    "          class_weight=class_weights)\n",
    "\n",
    "\n",
    "history = model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model2.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\nclassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "\n",
    "cmnn2 = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmnn2, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"NN Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model2 = SVC(kernel='rbf', C=15, gamma=0.001)\n",
    "svm_model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model2.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "cmsvc2 = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmsvc2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2 = LinearDiscriminantAnalysis()\n",
    "lda_model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lda = lda_model2.predict(X_test)\n",
    "\n",
    "print(\"accuraccy LDA:\", accuracy_score(y_test, y_pred_lda))\n",
    "print(classification_report(y_test, y_pred_lda))\n",
    "\n",
    "cmlda2 = confusion_matrix(y_test, y_pred_lda)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmlda2, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('LDA Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmrf1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"Random Forest - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmrf2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"Random Forest - Second Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmnb1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"Naive Bayes - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmnb2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"Naive Bayes - Second Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmnn1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"NN - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmnn2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"NN - Second Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmsvc1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"SVC - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmsvc2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"SVC - Second Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmlda1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"LDA - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmlda2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"LDA - Second Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding optimal parameters for the updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 220, 250, 270, 300, 305, 310, 320],\n",
    "}\n",
    "\n",
    "rf2opt = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf2opt,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "best_rf2opt = grid_search.best_estimator_\n",
    "y_pred = best_rf2opt.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmrf2opt = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmrf2opt, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmrf2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"Random forest - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmrf2opt, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"Random forest - Optimal Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 5, 10, 15],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']  \n",
    "}\n",
    "\n",
    "svc2opt = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "best_svc2opt = grid_search.best_estimator_\n",
    "y_pred_svm = best_svc2opt.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "cmsvc2opt = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmsvc2opt, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmsvc2, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"SVC - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmsvc2opt, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"SVC - Optimal Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balancing emotion levels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/features.csv')\n",
    "\n",
    "idx = df[df['Emotion levels'] == \"X\"].index\n",
    "print(idx)\n",
    "\n",
    "df = df.drop(idx)\n",
    "\n",
    "df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "df['Emotion levels'] = df['Emotion levels'].apply(lambda x: 0 if x == 'XX' else 1)                  #specified/unspecified\n",
    "\n",
    "\n",
    "emotion_mapping = {\n",
    "    'ANG': 0,\n",
    "    'DIS': 1,\n",
    "    'FEA': 2,\n",
    "    'HAP': 3,\n",
    "    'SAD': 4,\n",
    "    'NEU': 5\n",
    "}\n",
    "\n",
    "df['emotion_numeric'] = df['Emotion'].map(emotion_mapping)\n",
    "\n",
    "df = df.drop(columns=['Emotion'])\n",
    "\n",
    "list_columns = ['mfcc_mean', 'mfcc_delta_mean', 'mfcc_delta2_mean', 'mel_spec_db_mean']\n",
    "\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(lambda x: np.mean(x) if isinstance(x, list) and len(x) > 0 else 0)\n",
    "\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "numeric_cols = numeric_cols.drop('emotion_numeric') if 'emotion_numeric' in numeric_cols else numeric_cols\n",
    "\n",
    "print(\"cols for standardization:\", list(numeric_cols))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"\\ndata after the standardization process:\")\n",
    "print(df[numeric_cols].head())\n",
    "\n",
    "df = df.drop(columns=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  \n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(6, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model3.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=50, batch_size=32, callbacks=[early_stop],\n",
    "          class_weight=class_weights)\n",
    "\n",
    "\n",
    "history = model3.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model3.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"\\nclassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "\n",
    "cmnn3 = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cmnn3, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"NN Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cmnn1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_title(\"NN - First Confusion Matrix\")\n",
    "\n",
    "sns.heatmap(cmnn3, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            yticklabels=['ANG','DIS','FEA','HAP','SAD','NEU'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_title(\"NN - Updated Data Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
